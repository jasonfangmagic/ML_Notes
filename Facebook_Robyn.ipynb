{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasonfangmagic/ML_Notes/blob/main/Facebook_Robyn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri8020_y1iFs"
      },
      "source": [
        "##Source \n",
        "https://facebookexperimental.github.io/Robyn/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpVSwp0Pw-sN"
      },
      "source": [
        "By applying these techniques on our historical data we will be\n",
        "able to identify how different channels and variables are\n",
        "contributing to our sales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTLHpJNlxf7B"
      },
      "source": [
        "##Two solutions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZc02m6NxOla"
      },
      "source": [
        "## 1. MTA Multi-touch attribution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsB8zeFixa6K"
      },
      "source": [
        "A marketing measurement approach that attempts to track users across devices and the ads they've seen in order to determine how the ads contribute to the path to purchase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sprm-BFRxqd5"
      },
      "source": [
        "Based on users\n",
        "\n",
        "behaviour's data\n",
        "\n",
        "Imprecise when business works offline too\n",
        "\n",
        "Requires user level data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru96bZ4lxwy0"
      },
      "source": [
        "## 2. MMX Marketing Mix Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b30pmAzx36y"
      },
      "source": [
        "Information about users are unnecessary\n",
        "\n",
        "Can handle mixed sales channels well\n",
        "\n",
        "Requires aggregate data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hVuU5-fCiw-0"
      },
      "outputs": [],
      "source": [
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8LJ1XoLlmDmJ"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "install.packages(\"Robyn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMYh91CgmPCY",
        "outputId": "077d05a1-a737-42ef-ccba-dda2bcdef480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "R[write to console]: \n",
            "\n",
            "R[write to console]: \n",
            "R[write to console]: The downloaded source packages are in\n",
            "\t‘/tmp/Rtmp0vFRU5/downloaded_packages’\n",
            "R[write to console]: \n",
            "R[write to console]: \n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "install.packages(\"reticulate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "B59x5DBlttrn"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "library(reticulate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "Sys.setenv(RETICULATE_PYTHON = \"~/.virtualenvs/r-reticulate/bin/python\")"
      ],
      "metadata": {
        "id": "88B1srNDB25F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "virtualenv_create(\"r-reticulate\")\n",
        "py_install(\"nevergrad\", pip = TRUE)\n",
        "use_virtualenv(\"r-reticulate\", required = TRUE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "Q0R3FZGjB7tY",
        "outputId": "cb89d0b1-37df-465d-cfb3-a76e9ccd862e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Python: /usr/bin/python3.7\n",
            "Creating virtual environment 'r-reticulate' ... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "R[write to console]: + '/usr/bin/python3.7' -m venv '/root/.virtualenvs/r-reticulate'\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAILED\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "R[write to console]: Error: Error creating virtual environment 'r-reticulate' [error code 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Error: Error creating virtual environment 'r-reticulate' [error code 1]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RInterpreterError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;31m# Need the newline in case the last line in code is a comment.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"withVisible({%s\\n})\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRRuntimeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m         return (super(SignatureTranslatedFunction, self)\n\u001b[0;32m--> 199\u001b[0;31m                 .__call__(*args, **kwargs))\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy2rpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rpy2/rinterface_lib/conversion.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;31m# TODO: test cdata is of the expected CType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rpy2/rinterface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror_occured\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_geterrmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRRuntimeError\u001b[0m: Error: Error creating virtual environment 'r-reticulate' [error code 1]\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRInterpreterError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6f101c8f01f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'virtualenv_create(\"r-reticulate\")\\npy_install(\"nevergrad\", pip = TRUE)\\nuse_virtualenv(\"r-reticulate\", required = TRUE)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-119>\u001b[0m in \u001b[0;36mR\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36mR\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36mR\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    761\u001b[0m                     \u001b[0mreturn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 \u001b[0mtext_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0mtext_output\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtext_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mwarning_or_other_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 raise RInterpreterError(code, str(exception),\n\u001b[0;32m--> 273\u001b[0;31m                                         warning_or_other_msg)\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0mtext_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtext_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRInterpreterError\u001b[0m: Failed to parse and evaluate line 'virtualenv_create(\"r-reticulate\")\\npy_install(\"nevergrad\", pip = TRUE)\\nuse_virtualenv(\"r-reticulate\", required = TRUE)'.\nR error message: \"Error: Error creating virtual environment 'r-reticulate' [error code 1]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76_9-kxQt44Z"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "data(\"dt_simulated_weekly\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "METx2CSguQzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec9a222-73cf-4d54-a460-8bc5bb130dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "R[write to console]: 'window_start' is adapted to the closest date contained in input data: 2016-11-21\n",
            "\n",
            "R[write to console]: 'window_end' is adapted to the closest date contained in input data: 2018-08-20\n",
            "\n",
            "R[write to console]: 'hyperparameters' are not provided yet. To include them, run robyn_inputs(InputCollect = InputCollect, hyperparameters = ...)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Observations: 208 (weeks)\n",
            "Input Table Columns (12):\n",
            "  Date: DATE\n",
            "  Dependent: revenue [revenue]\n",
            "  Paid Media: tv_S, ooh_S, print_S, facebook_I, search_clicks_P\n",
            "  Paid Media Spend: tv_S, ooh_S, print_S, facebook_S, search_S\n",
            "  Context: competitor_sales_B, events\n",
            "  Organic: newsletter\n",
            "  Prophet (Auto-generated): trend, season, holiday on DE\n",
            "  Unused: \n",
            "\n",
            "Date Range: 2015-11-23:2019-11-11\n",
            "Model Window: 2016-11-21:2018-08-20 (92 weeks)\n",
            "With Calibration: FALSE\n",
            "Custom parameters: None\n",
            "\n",
            "Adstock: geometric\n",
            "Hyper-parameters: \u001b[0;31mNot set yet\u001b[0m\n",
            "Total Observations: 208 (weeks)\n",
            "Input Table Columns (12):\n",
            "  Date: DATE\n",
            "  Dependent: revenue [revenue]\n",
            "  Paid Media: tv_S, ooh_S, print_S, facebook_I, search_clicks_P\n",
            "  Paid Media Spend: tv_S, ooh_S, print_S, facebook_S, search_S\n",
            "  Context: competitor_sales_B, events\n",
            "  Organic: newsletter\n",
            "  Prophet (Auto-generated): trend, season, holiday on DE\n",
            "  Unused: \n",
            "\n",
            "Date Range: 2015-11-23:2019-11-11\n",
            "Model Window: 2016-11-21:2018-08-20 (92 weeks)\n",
            "With Calibration: FALSE\n",
            "Custom parameters: None\n",
            "\n",
            "Adstock: geometric\n",
            "Hyper-parameters for media transformations:\n",
            "  facebook_S_alphas: [0.5, 3]\n",
            "  facebook_S_gammas: [0.3, 1]\n",
            "  facebook_S_thetas: [0, 0.3]\n",
            "  print_S_alphas: [0.5, 3]\n",
            "  print_S_gammas: [0.3, 1]\n",
            "  print_S_thetas: [0.1, 0.4]\n",
            "  tv_S_alphas: [0.5, 3]\n",
            "  tv_S_gammas: [0.3, 1]\n",
            "  tv_S_thetas: [0.3, 0.8]\n",
            "  search_S_alphas: [0.5, 3]\n",
            "  search_S_gammas: [0.3, 1]\n",
            "  search_S_thetas: [0, 0.3]\n",
            "  ooh_S_alphas: [0.5, 3]\n",
            "  ooh_S_gammas: [0.3, 1]\n",
            "  ooh_S_thetas: [0.1, 0.4]\n",
            "  newsletter_alphas: [0.5, 3]\n",
            "  newsletter_gammas: [0.3, 1]\n",
            "  newsletter_thetas: [0.1, 0.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "R[write to console]: Input data has 208 weeks in total: 2015-11-23 to 2019-11-11\n",
            "\n",
            "R[write to console]: Initial model is built on rolling window of 92 week: 2016-11-21 to 2018-08-20\n",
            "\n",
            "R[write to console]: Using geometric adstocking with 19 hyperparameters (19 to iterate + 0 fixed) on 2 cores\n",
            "\n",
            "R[write to console]: >>> Starting 5 trials with 2000 iterations each using TwoPointsDE nevergrad algorithm...\n",
            "\n",
            "R[write to console]:   Running trial 1 of 5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  |                                                                      |   0%"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# Copyright (c) Meta Platforms, Inc. and its affiliates.\n",
        "\n",
        "# This source code is licensed under the MIT license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "\n",
        "#############################################################################################\n",
        "####################         Facebook MMM Open Source - Robyn 3.7.1    ######################\n",
        "####################                    Quick guide                   #######################\n",
        "#############################################################################################\n",
        "\n",
        "################################################################\n",
        "#### Step 0: Setup environment\n",
        "\n",
        "## Install, load, and check (latest) version\n",
        "# install.packages(\"remotes\") # Install remotes first if you haven't already\n",
        "library(Robyn) # remotes::install_github(\"facebookexperimental/Robyn/R\")\n",
        "\n",
        "# Please, check if you have installed the latest version before running this demo. Update if not\n",
        "# https://github.com/facebookexperimental/Robyn/blob/main/R/DESCRIPTION#L4\n",
        "packageVersion(\"Robyn\")\n",
        "\n",
        "## Force multicore when using RStudio\n",
        "Sys.setenv(R_FUTURE_FORK_ENABLE = \"true\")\n",
        "options(future.fork.enable = TRUE)\n",
        "\n",
        "## Must install the python library Nevergrad once\n",
        "## ATTENTION: The latest Python 3.10 version may cause Nevergrad installation error\n",
        "## See here for more info about installing Python packages via reticulate\n",
        "## https://rstudio.github.io/reticulate/articles/python_packages.html\n",
        "\n",
        "# install.packages(\"reticulate\") # Install reticulate first if you haven't already\n",
        "# library(\"reticulate\") # Load the library\n",
        "\n",
        "## Option 1: nevergrad installation via PIP (no additional installs)\n",
        "# virtualenv_create(\"r-reticulate\")\n",
        "# use_virtualenv(\"r-reticulate\", required = TRUE)\n",
        "# py_install(\"nevergrad\", pip = TRUE)\n",
        "# py_config() # Check your python version and configurations\n",
        "## In case nevergrad still can't be installed,\n",
        "# Sys.setenv(RETICULATE_PYTHON = \"~/.virtualenvs/r-reticulate/bin/python\")\n",
        "# Reset your R session and re-install Nevergrad with option 1\n",
        "\n",
        "## Option 2: nevergrad installation via conda (must have conda installed)\n",
        "# conda_create(\"r-reticulate\", \"Python 3.9\") # Only works with <= Python 3.9 sofar\n",
        "# use_condaenv(\"r-reticulate\")\n",
        "# conda_install(\"r-reticulate\", \"nevergrad\", pip=TRUE)\n",
        "# py_config() # Check your python version and configurations\n",
        "## In case nevergrad still can't be installed,\n",
        "## please locate your python file and run this line with your path:\n",
        "# use_python(\"~/Library/r-miniconda/envs/r-reticulate/bin/python3.9\")\n",
        "# Alternatively, force Python path for reticulate with this:\n",
        "# Sys.setenv(RETICULATE_PYTHON = \"~/Library/r-miniconda/envs/r-reticulate/bin/python3.9\")\n",
        "# Finally, reset your R session and re-install Nevergrad with option 2\n",
        "\n",
        "# Check this issue for more ideas to debug your reticulate/nevergrad issues:\n",
        "# https://github.com/facebookexperimental/Robyn/issues/189\n",
        "\n",
        "################################################################\n",
        "#### Step 1: Load data\n",
        "\n",
        "## Check simulated dataset or load your own dataset\n",
        "data(\"dt_simulated_weekly\")\n",
        "head(dt_simulated_weekly)\n",
        "\n",
        "## Check holidays from Prophet\n",
        "# 59 countries included. If your country is not included, please manually add it.\n",
        "# Tipp: any events can be added into this table, school break, events etc.\n",
        "data(\"dt_prophet_holidays\")\n",
        "head(dt_prophet_holidays)\n",
        "\n",
        "## Set robyn_object. It must have extension .RDS. The object name can be different than Robyn:\n",
        "robyn_object <- \"~/Desktop/MyRobyn.RDS\"\n",
        "\n",
        "################################################################\n",
        "#### Step 2a: For first time user: Model specification in 4 steps\n",
        "\n",
        "#### 2a-1: First, specify input variables\n",
        "\n",
        "## -------------------------------- NOTE v3.6.0 CHANGE !!! ---------------------------------- ##\n",
        "## All sign control are now automatically provided: \"positive\" for media & organic variables\n",
        "## and \"default\" for all others. User can still customise signs if necessary. Documentation\n",
        "## is available in ?robyn_inputs\n",
        "## ------------------------------------------------------------------------------------------ ##\n",
        "InputCollect <- robyn_inputs(\n",
        "  dt_input = dt_simulated_weekly,\n",
        "  dt_holidays = dt_prophet_holidays,\n",
        "  date_var = \"DATE\", # date format must be \"2020-01-01\"\n",
        "  dep_var = \"revenue\", # there should be only one dependent variable\n",
        "  dep_var_type = \"revenue\", # \"revenue\" (ROI) or \"conversion\" (CPA)\n",
        "  prophet_vars = c(\"trend\", \"season\", \"holiday\"), # \"trend\",\"season\", \"weekday\" & \"holiday\"\n",
        "  prophet_country = \"DE\", # input one country. dt_prophet_holidays includes 59 countries by default\n",
        "  context_vars = c(\"competitor_sales_B\", \"events\"), # e.g. competitors, discount, unemployment etc\n",
        "  paid_media_spends = c(\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_S\", \"search_S\"), # mandatory input\n",
        "  paid_media_vars = c(\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_I\", \"search_clicks_P\"), # mandatory.\n",
        "  # paid_media_vars must have same order as paid_media_spends. Use media exposure metrics like\n",
        "  # impressions, GRP etc. If not applicable, use spend instead.\n",
        "  organic_vars = c(\"newsletter\"), # marketing activity without media spend\n",
        "  factor_vars = c(\"events\"), # specify which variables in context_vars or organic_vars are factorial\n",
        "  window_start = \"2016-11-23\",\n",
        "  window_end = \"2018-08-22\",\n",
        "  adstock = \"geometric\" # geometric, weibull_cdf or weibull_pdf.\n",
        ")\n",
        "print(InputCollect)\n",
        "\n",
        "#### 2a-2: Second, define and add hyperparameters\n",
        "\n",
        "## -------------------------------- NOTE v3.6.0 CHANGE !!! ---------------------------------- ##\n",
        "## Default media variable for modelling has changed from paid_media_vars to paid_media_spends.\n",
        "## hyperparameter names needs to be base on paid_media_spends names. Run:\n",
        "hyper_names(adstock = InputCollect$adstock, all_media = InputCollect$all_media)\n",
        "## to see correct hyperparameter names. Check GitHub homepage for background of change.\n",
        "## Also calibration_input are required to be spend names.\n",
        "## ------------------------------------------------------------------------------------------ ##\n",
        "\n",
        "## Guide to setup & understand hyperparameters\n",
        "\n",
        "## 1. IMPORTANT: set plot = TRUE to see helper plots of hyperparameter's effect in transformation\n",
        "plot_adstock(plot = FALSE)\n",
        "plot_saturation(plot = FALSE)\n",
        "\n",
        "## 2. Get correct hyperparameter names:\n",
        "# All variables in paid_media_spends and organic_vars require hyperparameter and will be\n",
        "# transformed by adstock & saturation.\n",
        "# Run hyper_names() as above to get correct media hyperparameter names. All names in\n",
        "# hyperparameters must equal names from hyper_names(), case sensitive.\n",
        "# Run ?hyper_names to check parameter definition.\n",
        "\n",
        "## 3. Hyperparameter interpretation & recommendation:\n",
        "\n",
        "## Geometric adstock: Theta is the only parameter and means fixed decay rate. Assuming TV\n",
        "# spend on day 1 is 100€ and theta = 0.7, then day 2 has 100*0.7=70€ worth of effect\n",
        "# carried-over from day 1, day 3 has 70*0.7=49€ from day 2 etc. Rule-of-thumb for common\n",
        "# media genre: TV c(0.3, 0.8), OOH/Print/Radio c(0.1, 0.4), digital c(0, 0.3)\n",
        "\n",
        "## Weibull CDF adstock: The Cumulative Distribution Function of Weibull has two parameters\n",
        "# , shape & scale, and has flexible decay rate, compared to Geometric adstock with fixed\n",
        "# decay rate. The shape parameter controls the shape of the decay curve. Recommended\n",
        "# bound is c(0.0001, 2). The larger the shape, the more S-shape. The smaller, the more\n",
        "# L-shape. Scale controls the inflexion point of the decay curve. We recommend very\n",
        "# conservative bounce of c(0, 0.1), because scale increases the adstock half-life greatly.\n",
        "\n",
        "## Weibull PDF adstock: The Probability Density Function of the Weibull also has two\n",
        "# parameters, shape & scale, and also has flexible decay rate as Weibull CDF. The\n",
        "# difference is that Weibull PDF offers lagged effect. When shape > 2, the curve peaks\n",
        "# after x = 0 and has NULL slope at x = 0, enabling lagged effect and sharper increase and\n",
        "# decrease of adstock, while the scale parameter indicates the limit of the relative\n",
        "# position of the peak at x axis; when 1 < shape < 2, the curve peaks after x = 0 and has\n",
        "# infinite positive slope at x = 0, enabling lagged effect and slower increase and decrease\n",
        "# of adstock, while scale has the same effect as above; when shape = 1, the curve peaks at\n",
        "# x = 0 and reduces to exponential decay, while scale controls the inflexion point; when\n",
        "# 0 < shape < 1, the curve peaks at x = 0 and has increasing decay, while scale controls\n",
        "# the inflexion point. When all possible shapes are relevant, we recommend c(0.0001, 10)\n",
        "# as bounds for shape; when only strong lagged effect is of interest, we recommend\n",
        "# c(2.0001, 10) as bound for shape. In all cases, we recommend conservative bound of\n",
        "# c(0, 0.1) for scale. Due to the great flexibility of Weibull PDF, meaning more freedom\n",
        "# in hyperparameter spaces for Nevergrad to explore, it also requires larger iterations\n",
        "# to converge.\n",
        "\n",
        "## Hill function for saturation: Hill function is a two-parametric function in Robyn with\n",
        "# alpha and gamma. Alpha controls the shape of the curve between exponential and s-shape.\n",
        "# Recommended bound is c(0.5, 3). The larger the alpha, the more S-shape. The smaller, the\n",
        "# more C-shape. Gamma controls the inflexion point. Recommended bounce is c(0.3, 1). The\n",
        "# larger the gamma, the later the inflection point in the response curve.\n",
        "\n",
        "## 4. Set individual hyperparameter bounds. They either contain two values e.g. c(0, 0.5),\n",
        "# or only one value, in which case you'd \"fix\" that hyperparameter.\n",
        "\n",
        "# Run hyper_limits() to check maximum upper and lower bounds by range\n",
        "# Example hyperparameters ranges for Geometric adstock\n",
        "hyperparameters <- list(\n",
        "  facebook_S_alphas = c(0.5, 3),\n",
        "  facebook_S_gammas = c(0.3, 1),\n",
        "  facebook_S_thetas = c(0, 0.3),\n",
        "  print_S_alphas = c(0.5, 3),\n",
        "  print_S_gammas = c(0.3, 1),\n",
        "  print_S_thetas = c(0.1, 0.4),\n",
        "  tv_S_alphas = c(0.5, 3),\n",
        "  tv_S_gammas = c(0.3, 1),\n",
        "  tv_S_thetas = c(0.3, 0.8),\n",
        "  search_S_alphas = c(0.5, 3),\n",
        "  search_S_gammas = c(0.3, 1),\n",
        "  search_S_thetas = c(0, 0.3),\n",
        "  ooh_S_alphas = c(0.5, 3),\n",
        "  ooh_S_gammas = c(0.3, 1),\n",
        "  ooh_S_thetas = c(0.1, 0.4),\n",
        "  newsletter_alphas = c(0.5, 3),\n",
        "  newsletter_gammas = c(0.3, 1),\n",
        "  newsletter_thetas = c(0.1, 0.4)\n",
        ")\n",
        "\n",
        "# Example hyperparameters ranges for Weibull CDF adstock\n",
        "# facebook_S_alphas = c(0.5, 3)\n",
        "# facebook_S_gammas = c(0.3, 1)\n",
        "# facebook_S_shapes = c(0.0001, 2)\n",
        "# facebook_S_scales = c(0, 0.1)\n",
        "\n",
        "# Example hyperparameters ranges for Weibull PDF adstock\n",
        "# facebook_S_alphas = c(0.5, 3\n",
        "# facebook_S_gammas = c(0.3, 1)\n",
        "# facebook_S_shapes = c(0.0001, 10)\n",
        "# facebook_S_scales = c(0, 0.1)\n",
        "\n",
        "#### 2a-3: Third, add hyperparameters into robyn_inputs()\n",
        "\n",
        "InputCollect <- robyn_inputs(InputCollect = InputCollect, hyperparameters = hyperparameters)\n",
        "print(InputCollect)\n",
        "\n",
        "#### 2a-4: Fourth (optional), model calibration / add experimental input\n",
        "\n",
        "## Guide for calibration source\n",
        "\n",
        "# 1. We strongly recommend to use experimental and causal results that are considered\n",
        "# ground truth to calibrate MMM. Usual experiment types are people-based (e.g. Facebook\n",
        "# conversion lift) and geo-based (e.g. Facebook GeoLift).\n",
        "# 2. Currently, Robyn only accepts point-estimate as calibration input. For example, if\n",
        "# 10k$ spend is tested against a hold-out for channel A, then input the incremental\n",
        "# return as point-estimate as the example below.\n",
        "# 3. The point-estimate has to always match the spend in the variable. For example, if\n",
        "# channel A usually has $100K weekly spend and the experimental holdout is 70%, input\n",
        "# the point-estimate for the $30K, not the $70K.\n",
        "\n",
        "## -------------------------------- NOTE v3.6.4 CHANGE !!! ---------------------------------- ##\n",
        "## Calibration channels need to be paid_media_spends or organic_vars name.\n",
        "## ------------------------------------------------------------------------------------------ ##\n",
        "# calibration_input <- data.frame(\n",
        "#   # channel name must in paid_media_vars\n",
        "#   channel = c(\"facebook_S\",  \"tv_S\", \"facebook_S\", \"newsletter\"),\n",
        "#   # liftStartDate must be within input data range\n",
        "#   liftStartDate = as.Date(c(\"2018-05-01\", \"2018-04-03\", \"2018-07-01\", \"2017-12-01\")),\n",
        "#   # liftEndDate must be within input data range\n",
        "#   liftEndDate = as.Date(c(\"2018-06-10\", \"2018-06-03\", \"2018-07-20\", \"2017-12-31\")),\n",
        "#   # Provided value must be tested on same campaign level in model and same metric as dep_var_type\n",
        "#   liftAbs = c(400000, 300000, 200000, 200),\n",
        "#   # Spend within experiment: should match within a 10% error your spend on date range for each channel from dt_input\n",
        "#   spend = c(421000, 7100, 240000, 0),\n",
        "#   # Confidence: if frequentist experiment, you may use 1 - pvalue\n",
        "#   confidence = c(0.85, 0.8, 0.99, 0.95),\n",
        "#   # KPI measured: must match your dep_var\n",
        "#   metric = c(\"revenue\", \"revenue\", \"revenue\", \"revenue\")\n",
        "# )\n",
        "# InputCollect <- robyn_inputs(InputCollect = InputCollect, calibration_input = calibration_input)\n",
        "\n",
        "\n",
        "################################################################\n",
        "#### Step 2b: For known model specification, setup in one single step\n",
        "\n",
        "## Specify hyperparameters as in 2a-2 and optionally calibration as in 2a-4 and provide them directly in robyn_inputs()\n",
        "\n",
        "# InputCollect <- robyn_inputs(\n",
        "#   dt_input = dt_simulated_weekly\n",
        "#   ,dt_holidays = dt_prophet_holidays\n",
        "#   ,date_var = \"DATE\"\n",
        "#   ,dep_var = \"revenue\"\n",
        "#   ,dep_var_type = \"revenue\"\n",
        "#   ,prophet_vars = c(\"trend\", \"season\", \"holiday\")\n",
        "#   ,prophet_country = \"DE\"\n",
        "#   ,context_vars = c(\"competitor_sales_B\", \"events\")\n",
        "#   ,paid_media_spends = c(\"tv_S\", \"ooh_S\",\t\"print_S\", \"facebook_S\", \"search_S\")\n",
        "#   ,paid_media_vars = c(\"tv_S\", \"ooh_S\", \t\"print_S\", \"facebook_I\", \"search_clicks_P\")\n",
        "#   ,organic_vars = c(\"newsletter\")\n",
        "#   ,factor_vars = c(\"events\")\n",
        "#   ,window_start = \"2016-11-23\"\n",
        "#   ,window_end = \"2018-08-22\"\n",
        "#   ,adstock = \"geometric\"\n",
        "#   ,hyperparameters = hyperparameters # as in 2a-2 above\n",
        "#   #,calibration_input = dt_calibration # as in 2a-4 above\n",
        "# )\n",
        "\n",
        "# #### Experimental 3.7.1: JSON export and import\n",
        "# robyn_write(InputCollect, dir = \"~/Desktop\")\n",
        "# InputCollect <- robyn_inputs(\n",
        "#   dt_input = dt_simulated_weekly,\n",
        "#   dt_holidays = dt_prophet_holidays,\n",
        "#   json_file = \"~/Desktop/RobynModel-inputs.json\")\n",
        "\n",
        "################################################################\n",
        "#### Step 3: Build initial model\n",
        "\n",
        "## Run all trials and iterations. Use ?robyn_run to check parameter definition\n",
        "OutputModels <- robyn_run(\n",
        "  InputCollect = InputCollect, # feed in all model specification\n",
        "  # cores = NULL, # default to max available\n",
        "  # add_penalty_factor = FALSE, # Untested feature. Use with caution.\n",
        "  iterations = 2000, # recommended for the dummy dataset\n",
        "  trials = 5, # recommended for the dummy dataset\n",
        "  outputs = FALSE # outputs = FALSE disables direct model output - robyn_outputs()\n",
        ")\n",
        "print(OutputModels)\n",
        "\n",
        "## Check MOO (multi-objective optimization) convergence plots\n",
        "OutputModels$convergence$moo_distrb_plot\n",
        "OutputModels$convergence$moo_cloud_plot\n",
        "# check convergence rules ?robyn_converge\n",
        "\n",
        "## Calculate Pareto optimality, cluster and export results and plots. See ?robyn_outputs\n",
        "OutputCollect <- robyn_outputs(\n",
        "  InputCollect, OutputModels,\n",
        "  pareto_fronts = 3,\n",
        "  # calibration_constraint = 0.1, # range c(0.01, 0.1) & default at 0.1\n",
        "  csv_out = \"pareto\", # \"pareto\" or \"all\"\n",
        "  clusters = TRUE, # Set to TRUE to cluster similar models by ROAS. See ?robyn_clusters\n",
        "  plot_pareto = TRUE, # Set to FALSE to deactivate plotting and saving model one-pagers\n",
        "  plot_folder = robyn_object # path for plots export\n",
        ")\n",
        "print(OutputCollect)\n",
        "\n",
        "## 4 csv files are exported into the folder for further usage. Check schema here:\n",
        "## https://github.com/facebookexperimental/Robyn/blob/main/demo/schema.R\n",
        "# pareto_hyperparameters.csv, hyperparameters per Pareto output model\n",
        "# pareto_aggregated.csv, aggregated decomposition per independent variable of all Pareto output\n",
        "# pareto_media_transform_matrix.csv, all media transformation vectors\n",
        "# pareto_alldecomp_matrix.csv, all decomposition vectors of independent variables\n",
        "\n",
        "\n",
        "################################################################\n",
        "#### Step 4: Select and save the initial model\n",
        "\n",
        "## Compare all model one-pagers and select one that mostly reflects your business reality\n",
        "print(OutputCollect)\n",
        "\n",
        "select_model <- \"1_26_16\" # select one from above\n",
        "ExportedModel <- robyn_save(\n",
        "  robyn_object = robyn_object, # model object location and name\n",
        "  select_model = select_model, # selected model ID\n",
        "  InputCollect = InputCollect,\n",
        "  OutputCollect = OutputCollect\n",
        ")\n",
        "print(ExportedModel)\n",
        "# plot(ExportedModel)\n",
        "\n",
        "#### Since 3.7.1: JSON export and import (faster and lighter)\n",
        "ExportedModelJSON <- robyn_write(InputCollect, OutputCollect, select_model)\n",
        "print(ExportedModelJSON)\n",
        "\n",
        "################################################################\n",
        "#### Step 5: Get budget allocation based on the selected model above\n",
        "\n",
        "## Budget allocation result requires further validation. Please use this recommendation with caution.\n",
        "## Don't interpret budget allocation result if selected model above doesn't meet business expectation.\n",
        "\n",
        "# Check media summary for selected model\n",
        "print(ExportedModel)\n",
        "\n",
        "# Run ?robyn_allocator to check parameter definition\n",
        "# Run the \"max_historical_response\" scenario: \"What's the revenue lift potential with the\n",
        "# same historical spend level and what is the spend mix?\"\n",
        "AllocatorCollect1 <- robyn_allocator(\n",
        "  InputCollect = InputCollect,\n",
        "  OutputCollect = OutputCollect,\n",
        "  select_model = select_model,\n",
        "  scenario = \"max_historical_response\",\n",
        "  channel_constr_low = 0.7,\n",
        "  channel_constr_up = c(1.2, 1.5, 1.5, 1.5, 1.5),\n",
        "  export = TRUE,\n",
        "  date_min = \"2016-11-21\",\n",
        "  date_max = \"2018-08-20\"\n",
        ")\n",
        "print(AllocatorCollect1)\n",
        "# plot(AllocatorCollect1)\n",
        "\n",
        "# Run the \"max_response_expected_spend\" scenario: \"What's the maximum response for a given\n",
        "# total spend based on historical saturation and what is the spend mix?\" \"optmSpendShareUnit\"\n",
        "# is the optimum spend share.\n",
        "AllocatorCollect2 <- robyn_allocator(\n",
        "  InputCollect = InputCollect,\n",
        "  OutputCollect = OutputCollect,\n",
        "  select_model = select_model,\n",
        "  scenario = \"max_response_expected_spend\",\n",
        "  channel_constr_low = c(0.7, 0.7, 0.7, 0.7, 0.7),\n",
        "  channel_constr_up = c(1.2, 1.5, 1.5, 1.5, 1.5),\n",
        "  expected_spend = 1000000, # Total spend to be simulated\n",
        "  expected_spend_days = 7, # Duration of expected_spend in days\n",
        "  export = TRUE\n",
        ")\n",
        "print(AllocatorCollect2)\n",
        "AllocatorCollect2$dt_optimOut\n",
        "# plot(AllocatorCollect2)\n",
        "\n",
        "## A csv is exported into the folder for further usage. Check schema here:\n",
        "## https://github.com/facebookexperimental/Robyn/blob/main/demo/schema.R\n",
        "\n",
        "## QA optimal response\n",
        "# Pick any media variable: InputCollect$all_media\n",
        "select_media <- \"search_S\"\n",
        "# For paid_media_spends set metric_value as your optimal spend\n",
        "metric_value <- AllocatorCollect1$dt_optimOut$optmSpendUnit[\n",
        "  AllocatorCollect1$dt_optimOut$channels == select_media\n",
        "]\n",
        "# # For paid_media_vars and organic_vars, manually pick a value\n",
        "# metric_value <- 10000\n",
        "\n",
        "if (TRUE) {\n",
        "  optimal_response_allocator <- AllocatorCollect1$dt_optimOut$optmResponseUnit[\n",
        "    AllocatorCollect1$dt_optimOut$channels == select_media\n",
        "  ]\n",
        "  optimal_response <- robyn_response(\n",
        "    robyn_object = robyn_object,\n",
        "    select_build = 0,\n",
        "    media_metric = select_media,\n",
        "    metric_value = metric_value\n",
        "  )\n",
        "  plot(optimal_response$plot)\n",
        "  if (length(optimal_response_allocator) > 0) {\n",
        "    cat(\"QA if results from robyn_allocator and robyn_response agree: \")\n",
        "    cat(round(optimal_response_allocator) == round(optimal_response$response), \"( \")\n",
        "    cat(optimal_response$response, \"==\", optimal_response_allocator, \")\\n\")\n",
        "  }\n",
        "}\n",
        "\n",
        "################################################################\n",
        "#### Step 6: Model refresh based on selected model and saved Robyn.RDS object - Alpha\n",
        "\n",
        "## NOTE: must run robyn_save to select and save an initial model first, before refreshing below\n",
        "## The robyn_refresh() function is suitable for updating within \"reasonable periods\"\n",
        "## Two situations are considered better to rebuild model:\n",
        "## 1, most data is new. If initial model has 100 weeks and 80 weeks new data is added in refresh,\n",
        "## it might be better to rebuild the model\n",
        "## 2, new variables are added\n",
        "\n",
        "# Run ?robyn_refresh to check parameter definition\n",
        "Robyn <- robyn_refresh(\n",
        "  robyn_object = robyn_object,\n",
        "  dt_input = dt_simulated_weekly,\n",
        "  dt_holidays = dt_prophet_holidays,\n",
        "  refresh_steps = 4,\n",
        "  refresh_mode = \"manual\",\n",
        "  refresh_iters = 100, # 1k is estimation. Use refresh_mode = \"manual\" to try out.\n",
        "  refresh_trials = 1\n",
        ")\n",
        "\n",
        "## Besides plots: there are 4 CSV outputs saved in the folder for further usage\n",
        "# report_hyperparameters.csv, hyperparameters of all selected model for reporting\n",
        "# report_aggregated.csv, aggregated decomposition per independent variable\n",
        "# report_media_transform_matrix.csv, all media transformation vectors\n",
        "# report_alldecomp_matrix.csv,all decomposition vectors of independent variables\n",
        "\n",
        "# Export the refreshed model you wish to export (1 es the original, 2 the first refresh, ...)\n",
        "last_refresh_num <- sum(grepl(\"listRefresh\", names(Robyn))) + 1 # last one?\n",
        "ExportedRefreshModel <- robyn_save(\n",
        "  robyn_object = robyn_object,\n",
        "  select_model = Robyn$refresh$selectIDs[last_refresh_num],\n",
        "  InputCollect = Robyn[[last_refresh_num]]$InputCollect,\n",
        "  OutputCollect = Robyn[[last_refresh_num]]$OutputCollect\n",
        ")\n",
        "\n",
        "################################################################\n",
        "#### Step 7: Get budget allocation recommendation based on selected refresh runs\n",
        "\n",
        "# Run ?robyn_allocator to check parameter definition\n",
        "AllocatorCollect <- robyn_allocator(\n",
        "  robyn_object = robyn_object,\n",
        "  scenario = \"max_response_expected_spend\",\n",
        "  channel_constr_low = c(0.7, 0.7, 0.7, 0.7, 0.7),\n",
        "  channel_constr_up = c(1.2, 1.5, 1.5, 1.5, 1.5),\n",
        "  expected_spend = 2000000, # Total spend to be simulated\n",
        "  expected_spend_days = 14 # Duration of expected_spend in days\n",
        ")\n",
        "print(AllocatorCollect)\n",
        "# plot(AllocatorCollect)\n",
        "\n",
        "################################################################\n",
        "#### Step 8: get marginal returns\n",
        "\n",
        "## Example of how to get marginal ROI of next 1000$ from the 80k spend level for search channel\n",
        "\n",
        "# Run ?robyn_response to check parameter definition\n",
        "\n",
        "## -------------------------------- NOTE v3.6.0 CHANGE !!! ---------------------------------- ##\n",
        "## The robyn_response() function can now output response for both spends and exposures (imps,\n",
        "## GRP, newsletter sendings etc.) as well as plotting individual saturation curves. New\n",
        "## argument names \"media_metric\" and \"metric_value\" instead of \"paid_media_var\" and \"spend\"\n",
        "## are now used to accommodate this change. Also the returned output is a list now and\n",
        "## contains also the plot.\n",
        "## ------------------------------------------------------------------------------------------ ##\n",
        "\n",
        "# Get response for 80k from result saved in robyn_object\n",
        "Spend1 <- 60000\n",
        "Response1 <- robyn_response(\n",
        "  robyn_object = robyn_object,\n",
        "  # select_build = 1, # 2 means the second refresh model. 0 means the initial model\n",
        "  media_metric = \"search_S\",\n",
        "  metric_value = Spend1\n",
        ")\n",
        "Response1$response / Spend1 # ROI for search 80k\n",
        "Response1$plot\n",
        "\n",
        "# Get response for 81k\n",
        "Spend2 <- Spend1 + 1000\n",
        "Response2 <- robyn_response(\n",
        "  robyn_object = robyn_object,\n",
        "  # select_build = 1,\n",
        "  media_metric = \"search_S\",\n",
        "  metric_value = Spend2\n",
        ")\n",
        "Response2$response / Spend2 # ROI for search 81k\n",
        "Response2$plot\n",
        "\n",
        "# Marginal ROI of next 1000$ from 80k spend level for search\n",
        "(Response2$response - Response1$response) / (Spend2 - Spend1)\n",
        "\n",
        "## Example of getting paid media exposure response curves\n",
        "imps <- 50000000\n",
        "response_imps <- robyn_response(\n",
        "  robyn_object = robyn_object,\n",
        "  media_metric = \"facebook_I\",\n",
        "  metric_value = imps\n",
        ")\n",
        "response_imps$response / imps * 1000\n",
        "response_imps$plot\n",
        "\n",
        "## Example of getting organic media exposure response curves\n",
        "sendings <- 30000\n",
        "response_sending <- robyn_response(\n",
        "  robyn_object = robyn_object,\n",
        "  media_metric = \"newsletter\",\n",
        "  metric_value = sendings\n",
        ")\n",
        "response_sending$response / sendings * 1000\n",
        "response_sending$plot\n",
        "\n",
        "################################################################\n",
        "#### Optional: recreate old models and replicate results\n",
        "\n",
        "# From an exported JSON file (which is created automatically when exporting a model)\n",
        "# we can re-create a previously trained model and outputs. Note: we need to provide\n",
        "# the original and the holidays dataset, which are NOT stored in the JSON file.\n",
        "# Manually created: robyn_write(InputCollect, OutputCollect, select_model)\n",
        "json_file <- \"~/Desktop/Robyn_202208080929_init/RobynModel-1_26_16.json\"\n",
        "# json_data <- robyn_read(json_file) # Manual check on data stored\n",
        "\n",
        "InputCollectX <- robyn_inputs(\n",
        "  dt_input = dt_simulated_weekly,\n",
        "  dt_holidays = dt_prophet_holidays,\n",
        "  json_file = json_file)\n",
        "\n",
        "OutputCollectX <- robyn_run(\n",
        "  InputCollect = InputCollectX,\n",
        "  json_file = json_file,\n",
        "  export = FALSE)\n",
        "\n",
        "myModel <- robyn_write(InputCollectX, OutputCollectX)\n",
        "print(myModel)\n",
        "myModelPlot <- robyn_onepagers(InputCollectX, OutputCollectX)\n",
        "myModelPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQQ92UHPuUIe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Facebook Robyn",
      "provenance": [],
      "authorship_tag": "ABX9TyMj17ctcuvREMd6oh64QjvN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}